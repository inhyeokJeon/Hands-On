1. 서포트 벡터 머신의 근본 아이디어는 무엇인가요?
> 클래스 사이에 가능한 가장 넓은 도로는 내는 것이다. 두 클래스를 구분하는 결정 경계와 샘플 사이의 마진을 가능한 한 가장 크게 하는 것이 목적입니다.
2. 서포트 벡터가 무엇인가요?
> **서포트벡터** SVM이 훈련된 후에 경계를 포함해 도로에 놓인 어떤 샘플이다. 
> 결정 경계는 전적으로 서포트 벡터에 의해 결정된다. 서포트 벡터가 아닌 어떤 샘플도 영향을 주지 못합니다. 이런 샘플은 삭제하고 다른 샘플을 더 추가하거나,
> 다른 곳으로 이동시킬 수 있습니다. 샘플이 도로 밖에 있는 한 결정경계에 영향을 주지 못할 것이다. 예측을 계산할 떄는 전체 훈련 세트가 아니라 서포트벡터만 관여됩니다.
3. SVM을 사용할 때 입력값은 스케일이 왜 중요한가요?
> SVM은 클래스 사이에 가능한 한 가장 큰 도로를 내는 것이다. 
> 훈련 세트의 스케일이 맞지 않으면 크기가 작은 특성을 무시하는 경향이 있다.
4. SVM 분류기가 샘플을 분류할 떄 신뢰도 점수와 확률을 출력할 수 있나요?
> SVM 분류기는 테스트 샘플과 결정 경계 사이의 거리를 출력할 수 있으므로 이를 신뢰도 점수롤 사용할 수 있다. 
> 그러나 이 점수를 클래스 확률의 추정값으로 바로 변환할 수 는 없다. 사이킷런에서 SVM 모델을 만들 때 Probability= True 로 설정하면
> 훈련이 끝난 후 SVM의 점수에 로지스틱 회귀를 훈련시켜 확률을 계산합니다.
> 이 설정은 SVM 모델에 predict_proba()와 predict_log_proba() 메서드를 추가시킵니다.
5. 수백만 개의 샘플과 수백 개의 특성을 가진 훈련 세트에 SVM 모델을 훈련시킬면 원 문제와 쌍대 문제 중 어떤 것을 사용해야 하나요?
> 커널 SVM은 쌍대 형식만 사용할 수 있기 때문에 이 질문은 선형 SVM에만 해당합니다.
> 원 문제의 계산 복잡도는 훈련 샘플 수 m에 비례하지만, 쌍대 형식의 계산 복잡도는 m^2과 m^3사이의 값에 비례합니다.
> 그러므로 수백만 개의 샘플 이 있으면 쌍대 형식은 너무 느려 질 것이므로 원 문제를 사용해야 한다.
6. RBF 커널을 사용해 SVM 분기를 훈련시켰더니 훈련 세트에 과소적합된 것 같습니다. r(gamma)를 증가시켜야 할까요, 감소싴야 할까요? C의 경우는 어떤가요?
> 과소적합 -> 규제가 너무크다 -> gamma 나 C 값을 둘다 증가 시켜야한다.
7. 이미 만들어진 뼤 QP알고리즘 라이브러리를 사용해 소프트 마진 선형 SVM 분류기를 학습시키려면 QP 매개변수(H,f,A,b)를 어떻게 지정해야 하나요?
> ??
8. 선형적으로 분리되는 데이터셋에 LinearSVC를 훈련시켜보세요. 그런 다음 같은 데이터셋에 SVC와 SGDClassifier를 적용해보세요. 거의 비슷한 모델이 만들어지는지 확인해보세요.
9. MNIST 데이터셋에 SVM 분류기를 훈련시켜보세요. SVM 분류기는 이진 분류기라서 OvR 전략을 사용해 10개의 숫자를 분류해야 합니다. 처리 속도를 높이기 위해 작은 검증 세트로 하이퍼파라미터를 조정하는 것이 좋습니다. 어느 정도까지 정확도를 높일 수 있나요?
10. 캘리포니아 주택 가격 데이터셋에 SVM 회귀를 훈련시켜 보세요.