> 1. 데이터 셋의 차원을 축소하는 주요 목적은 무엇인가요? 대표적인 단점은 무엇인가요?
> > 작업 속도를 높히기 위해서이다. 데이터를 시각화하고, 중요한 특성에 대한 통찰을 얻기 위해, 메모리 공간을 절약하기 위해(압축) 
> > 일부 정보가 손실 될 수 있다. 계산비용이 높다. 머신러닝 파이프라인의 복잡도를 증가시킨다. 이해하기 힘들다.
> 2. 차원의 저주란 무엇인가요?
> > 저차원에 없는 많은 문제가 고차원에서 발생한다.
> > 불필요한 많은 특성은 훈련을 느리게 하며, 좋은 솔루션을 찾기 힘들게 만든다.
> 3. 데이터셋의 차원을 축소시키고 나서 이 작업을 원복할 수 있나요? 할 수 있다면 어떻게 가능할까요?
> 가능하지 않다면 왜일까요?
> > 역변환방법을 가지고 있는 알고리즘은 가능합니다.
> > 그 외에는 데이터의 손실 때문에 다시 복구하기가 힘들다.
> 4. 매우 비선형적인 데이터셋의 차원을 축소하는데 PCA를 사용할 수 있을까요?
> > 가능합니다. 그러나 중요하지 않은 특성(차원)이 없다면 너무 많은 정보를 잃게한다. 이런것들은 적용하면 안된다
> 5. 설명된 분산을 95%로 지정한 PCA를 1000개의 차원을 가진 데이터셋에 적용한다고 가정하겠습니다.
> 결과 데이터셋의 차원은 얼마나 될까요?
> > 데이터 셋에 따라 다르다. 차원수에 대한 함수로 설명된 분산의 그래프를 그려보는 것이 데이터 셋에 내재된 차원 수를 대략 가늠할 수 있게 한다.
> 6. 기본 PCA, 점진적, 랜덤, 커널 각각은 어느 경우에 사용되나요?
> > 기본은 우선적으로 사용되며, 데이터셋이 메모리에 맞을때 가능하다.
> > 반면 점진적은 너무 데이터셋이 크면 쪼개서 사용한다.
> > 빠른속도를 기반으로 하기 때문에 차원을 크게 축소 시킬때 사용한다.
> > 커널은 비선형 데이터에 유용하다.
> 7. 어떤 데이터셋에 적용한 차원 축소 알고리즘의 성능을 어떻게 평가할 수 있을까요?
> > 역변환을 수행해 재구성 오차를 측정하면 평가 할 수 있다.
> 8. 두 개의 차원 축소 알고리즘을 연결할 수 있을까요?
> > 당연히 연결 가능하다. PCA로 불필요한 차원을 대폭 제거하고 난 다음 lle 같이 훨씬 느린 알고리즘을 적용하는 것이 대표적인 사례입니다.
> 9, 10 책 참고
> >