{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11th-examples-10.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Toj53bjbFi4si4kMtmvlet7ziof3e5U5","authorship_tag":"ABX9TyNdlJ3bvId/0b2VS6TyWSdo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"bhE-mUbjxdVI"},"source":["# CIFAR10에서 딥러닝"]},{"cell_type":"markdown","metadata":{"id":"mItn_j2AyeaU"},"source":["# setting"]},{"cell_type":"code","metadata":{"id":"d0EsPZiiyd4H","executionInfo":{"status":"ok","timestamp":1629301239033,"user_tz":-540,"elapsed":3127,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["# 파이썬 ≥3.5 필수\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# 사이킷런 ≥0.20 필수\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","# 텐서플로 ≥2.0 필수\n","import tensorflow as tf\n","from tensorflow import keras\n","assert tf.__version__ >= \"2.0\"\n","\n","%load_ext tensorboard\n","\n","# 공통 모듈 임포트\n","import numpy as np\n","import os\n","\n","# 노트북 실행 결과를 동일하게 유지하기 위해\n","np.random.seed(42)\n","\n","# 깔끔한 그래프 출력을 위해\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# 그림을 저장할 위치\n","PROJECT_ROOT_DIR = \".\"\n","CHAPTER_ID = \"deep\"\n","IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n","os.makedirs(IMAGES_PATH, exist_ok=True)\n","\n","def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n","    print(\"그림 저장:\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format=fig_extension, dpi=resolution)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLqQOXvzxaRC"},"source":["a. 문제: 100개의 뉴런을 가진 은닉층 20개로 심층 신경망을 만들어보세요(너무 많은 것 같지만 이 연습문제의 핵심입니다). He 초기화와 ELU 활성화 함수를 사용하세요."]},{"cell_type":"code","metadata":{"id":"pP8HKyBVxjED","executionInfo":{"status":"ok","timestamp":1629301240290,"user_tz":-540,"elapsed":1261,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3])) \n","for _ in range(20):\n","    model.add(keras.layers.Dense(100,\n","                                 activation=\"elu\", \n","                                 kernel_initializer=\"he_normal\")) "],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eN4e3Ch3xjNb"},"source":["b. Nadam 옵티마이저와 조기 종료를 사용하여 CIFAR10 데이터셋에 이 네트워크를 훈련하세요. keras.datasets.cifar10.load_ data()를 사용하여 데이터를 적재할 수 있습니다. 이 데이터셋은 10개의 클래스와 32×32 크기의 컬러 이미지 60,000개로 구성됩니다(50,000개는 훈련, 10,000개는 테스트). 따라서 10개의 뉴런과 소프트맥스 활성화 함수를 사용하는 출력층이 필요합니다. 모델 구조와 하이퍼파라미터를 바꿀 때마다 적절한 학습률을 찾아야 한다는 것을 기억하세요."]},{"cell_type":"code","metadata":{"id":"9KK6jwZ1zSVD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629301263866,"user_tz":-540,"elapsed":7690,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"ca3a513f-1243-45ac-8824-027a93dc4f72"},"source":["# data 적재\n","(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n","\n","X_train = X_train_full[5000:]\n","y_train = y_train_full[5000:]\n","X_valid = X_train_full[:5000]\n","y_valid = y_train_full[:5000]\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 4s 0us/step\n","170508288/170498071 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9sy0yzU7Eal","executionInfo":{"status":"ok","timestamp":1629301350943,"user_tz":-540,"elapsed":259,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"50bf6265-ef1b-420c-801f-1ef1842a2271"},"source":["print(X_train.shape)\n","print(len(X_train))\n","print(len(X_valid))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(45000, 32, 32, 3)\n","45000\n","5000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IL3s_Jaxj66","executionInfo":{"status":"ok","timestamp":1629286510450,"user_tz":-540,"elapsed":13,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"e0d772e5-b867-42b6-ebb5-326cceb304db"},"source":["#soft max 출력층 추가\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","# optimizer nadam\n","optimizer = keras.optimizers.Nadam(lr=5e-5)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_uPiJ7XH0Bck","executionInfo":{"status":"ok","timestamp":1629286510451,"user_tz":-540,"elapsed":13,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"c94fc018-7638-402d-c51f-727607ae823f"},"source":["print(X_train.shape)\n","print(y_train.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(45000, 32, 32, 3)\n","(45000, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j4hI_GuUznPx"},"source":["early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n","model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n","run_index = 1 # 모델을 훈련할 때마다 증가시킴\n","run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RjWSgY1zo6Q","executionInfo":{"status":"ok","timestamp":1629287706992,"user_tz":-540,"elapsed":51946,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"15a1b368-e6d5-49f6-cddf-c94e880a97a0"},"source":["model.fit(X_train, y_train, epochs=100,\n","          validation_data=(X_valid, y_valid),\n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","1407/1407 [==============================] - 24s 15ms/step - loss: 3.9882 - accuracy: 0.1750 - val_loss: 2.1041 - val_accuracy: 0.2368\n","Epoch 2/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 2.0415 - accuracy: 0.2551 - val_loss: 2.1067 - val_accuracy: 0.2406\n","Epoch 3/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.9307 - accuracy: 0.2952 - val_loss: 1.9628 - val_accuracy: 0.2804\n","Epoch 4/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.8526 - accuracy: 0.3225 - val_loss: 1.8137 - val_accuracy: 0.3412\n","Epoch 5/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7864 - accuracy: 0.3496 - val_loss: 1.8074 - val_accuracy: 0.3374\n","Epoch 6/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.7375 - accuracy: 0.3695 - val_loss: 1.7179 - val_accuracy: 0.3798\n","Epoch 7/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6983 - accuracy: 0.3864 - val_loss: 1.7286 - val_accuracy: 0.3726\n","Epoch 8/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6603 - accuracy: 0.4007 - val_loss: 1.6506 - val_accuracy: 0.4078\n","Epoch 9/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6316 - accuracy: 0.4096 - val_loss: 1.6569 - val_accuracy: 0.4046\n","Epoch 10/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.6065 - accuracy: 0.4223 - val_loss: 1.7023 - val_accuracy: 0.3868\n","Epoch 11/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5855 - accuracy: 0.4306 - val_loss: 1.6611 - val_accuracy: 0.3980\n","Epoch 12/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5656 - accuracy: 0.4377 - val_loss: 1.6067 - val_accuracy: 0.4190\n","Epoch 13/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5413 - accuracy: 0.4455 - val_loss: 1.6562 - val_accuracy: 0.4110\n","Epoch 14/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5322 - accuracy: 0.4483 - val_loss: 1.5883 - val_accuracy: 0.4214\n","Epoch 15/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.5091 - accuracy: 0.4580 - val_loss: 1.5885 - val_accuracy: 0.4298\n","Epoch 16/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4935 - accuracy: 0.4623 - val_loss: 1.5593 - val_accuracy: 0.4472\n","Epoch 17/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4792 - accuracy: 0.4717 - val_loss: 1.5737 - val_accuracy: 0.4378\n","Epoch 18/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4613 - accuracy: 0.4767 - val_loss: 1.5810 - val_accuracy: 0.4404\n","Epoch 19/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4520 - accuracy: 0.4804 - val_loss: 1.5534 - val_accuracy: 0.4460\n","Epoch 20/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4363 - accuracy: 0.4848 - val_loss: 1.5357 - val_accuracy: 0.4544\n","Epoch 21/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4258 - accuracy: 0.4874 - val_loss: 1.5442 - val_accuracy: 0.4524\n","Epoch 22/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.4152 - accuracy: 0.4930 - val_loss: 1.5188 - val_accuracy: 0.4626\n","Epoch 23/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.3996 - accuracy: 0.4997 - val_loss: 1.5674 - val_accuracy: 0.4394\n","Epoch 24/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3938 - accuracy: 0.5016 - val_loss: 1.5256 - val_accuracy: 0.4552\n","Epoch 25/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3789 - accuracy: 0.5072 - val_loss: 1.5248 - val_accuracy: 0.4550\n","Epoch 26/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3699 - accuracy: 0.5113 - val_loss: 1.5305 - val_accuracy: 0.4514\n","Epoch 27/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3598 - accuracy: 0.5120 - val_loss: 1.5222 - val_accuracy: 0.4642\n","Epoch 28/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3496 - accuracy: 0.5160 - val_loss: 1.5164 - val_accuracy: 0.4666\n","Epoch 29/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3418 - accuracy: 0.5204 - val_loss: 1.5185 - val_accuracy: 0.4638\n","Epoch 30/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3286 - accuracy: 0.5244 - val_loss: 1.5454 - val_accuracy: 0.4704\n","Epoch 31/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3190 - accuracy: 0.5288 - val_loss: 1.5797 - val_accuracy: 0.4522\n","Epoch 32/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3107 - accuracy: 0.5326 - val_loss: 1.5320 - val_accuracy: 0.4688\n","Epoch 33/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.3044 - accuracy: 0.5330 - val_loss: 1.5524 - val_accuracy: 0.4720\n","Epoch 34/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2925 - accuracy: 0.5391 - val_loss: 1.5319 - val_accuracy: 0.4722\n","Epoch 35/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2876 - accuracy: 0.5370 - val_loss: 1.5447 - val_accuracy: 0.4684\n","Epoch 36/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2774 - accuracy: 0.5444 - val_loss: 1.5484 - val_accuracy: 0.4640\n","Epoch 37/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2688 - accuracy: 0.5447 - val_loss: 1.5203 - val_accuracy: 0.4718\n","Epoch 38/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2615 - accuracy: 0.5480 - val_loss: 1.5360 - val_accuracy: 0.4702\n","Epoch 39/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2557 - accuracy: 0.5496 - val_loss: 1.5498 - val_accuracy: 0.4676\n","Epoch 40/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2465 - accuracy: 0.5550 - val_loss: 1.5285 - val_accuracy: 0.4712\n","Epoch 41/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2390 - accuracy: 0.5552 - val_loss: 1.5795 - val_accuracy: 0.4520\n","Epoch 42/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2286 - accuracy: 0.5607 - val_loss: 1.5237 - val_accuracy: 0.4768\n","Epoch 43/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2242 - accuracy: 0.5611 - val_loss: 1.5424 - val_accuracy: 0.4710\n","Epoch 44/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2198 - accuracy: 0.5634 - val_loss: 1.5500 - val_accuracy: 0.4664\n","Epoch 45/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2075 - accuracy: 0.5669 - val_loss: 1.5484 - val_accuracy: 0.4726\n","Epoch 46/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2019 - accuracy: 0.5705 - val_loss: 1.5154 - val_accuracy: 0.4812\n","Epoch 47/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1923 - accuracy: 0.5748 - val_loss: 1.5459 - val_accuracy: 0.4728\n","Epoch 48/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1880 - accuracy: 0.5740 - val_loss: 1.5457 - val_accuracy: 0.4702\n","Epoch 49/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1804 - accuracy: 0.5762 - val_loss: 1.5475 - val_accuracy: 0.4690\n","Epoch 50/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1692 - accuracy: 0.5796 - val_loss: 1.5445 - val_accuracy: 0.4804\n","Epoch 51/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1658 - accuracy: 0.5810 - val_loss: 1.5780 - val_accuracy: 0.4668\n","Epoch 52/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1569 - accuracy: 0.5847 - val_loss: 1.5531 - val_accuracy: 0.4758\n","Epoch 53/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1497 - accuracy: 0.5874 - val_loss: 1.5415 - val_accuracy: 0.4746\n","Epoch 54/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1456 - accuracy: 0.5904 - val_loss: 1.5599 - val_accuracy: 0.4838\n","Epoch 55/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1392 - accuracy: 0.5942 - val_loss: 1.5720 - val_accuracy: 0.4724\n","Epoch 56/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1327 - accuracy: 0.5936 - val_loss: 1.6125 - val_accuracy: 0.4532\n","Epoch 57/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1255 - accuracy: 0.5980 - val_loss: 1.5511 - val_accuracy: 0.4820\n","Epoch 58/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1205 - accuracy: 0.5978 - val_loss: 1.5838 - val_accuracy: 0.4586\n","Epoch 59/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.1135 - accuracy: 0.6021 - val_loss: 1.5641 - val_accuracy: 0.4840\n","Epoch 60/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.1067 - accuracy: 0.6039 - val_loss: 1.5795 - val_accuracy: 0.4744\n","Epoch 61/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1034 - accuracy: 0.6055 - val_loss: 1.5880 - val_accuracy: 0.4652\n","Epoch 62/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.0935 - accuracy: 0.6088 - val_loss: 1.6225 - val_accuracy: 0.4656\n","Epoch 63/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.0910 - accuracy: 0.6090 - val_loss: 1.5543 - val_accuracy: 0.4766\n","Epoch 64/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.0812 - accuracy: 0.6134 - val_loss: 1.6184 - val_accuracy: 0.4666\n","Epoch 65/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.0783 - accuracy: 0.6127 - val_loss: 1.6179 - val_accuracy: 0.4786\n","Epoch 66/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.0692 - accuracy: 0.6194 - val_loss: 1.6204 - val_accuracy: 0.4686\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1ac68ad550>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiOAREnA1Vb2","executionInfo":{"status":"ok","timestamp":1629287740531,"user_tz":-540,"elapsed":1751,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"47cfcd54-03f4-44e4-d391-1e8f9b0c856c"},"source":["model = keras.models.load_model(\"my_cifar10_model.h5\")\n","model.evaluate(X_valid, y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["157/157 [==============================] - 1s 3ms/step - loss: 1.5154 - accuracy: 0.4812\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.515366554260254, 0.4812000095844269]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"S-F3nP2-xkLy"},"source":["c. 배치 정규화를 추가하고 학습 곡선을 비교해보세요. 이전보다 빠르게 수렴하나요? 더 좋은 모델이 만들어지나요? 훈련 속도에는 어떤 영향을 미치나요?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qxu6bwwoxkT5","executionInfo":{"status":"ok","timestamp":1629285906123,"user_tz":-540,"elapsed":1220415,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"f1233b20-0392-4cf2-fb37-92d94e5f757d"},"source":["keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","model.add(keras.layers.BatchNormalization())\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n","    model.add(keras.layers.BatchNormalization())\n","    model.add(keras.layers.Activation(\"elu\"))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.Nadam(lr=5e-4)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n","model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n","run_index = 1 # 모델을 훈련할 때마다 증가시킴\n","run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n","\n","model.fit(X_train, y_train, epochs=100,\n","          validation_data=(X_valid, y_valid),\n","          callbacks=callbacks)\n","\n","model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n","model.evaluate(X_valid, y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","1407/1407 [==============================] - 39s 20ms/step - loss: 1.8462 - accuracy: 0.3394 - val_loss: 1.6817 - val_accuracy: 0.4050\n","Epoch 2/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.6724 - accuracy: 0.4062 - val_loss: 1.6114 - val_accuracy: 0.4206\n","Epoch 3/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.5975 - accuracy: 0.4324 - val_loss: 1.5443 - val_accuracy: 0.4548\n","Epoch 4/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.5475 - accuracy: 0.4485 - val_loss: 1.5008 - val_accuracy: 0.4596\n","Epoch 5/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.5069 - accuracy: 0.4644 - val_loss: 1.4573 - val_accuracy: 0.4838\n","Epoch 6/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.4688 - accuracy: 0.4789 - val_loss: 1.4245 - val_accuracy: 0.4936\n","Epoch 7/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.4379 - accuracy: 0.4880 - val_loss: 1.4211 - val_accuracy: 0.4932\n","Epoch 8/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.4104 - accuracy: 0.5000 - val_loss: 1.3960 - val_accuracy: 0.4980\n","Epoch 9/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.3859 - accuracy: 0.5096 - val_loss: 1.3824 - val_accuracy: 0.5046\n","Epoch 10/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.3628 - accuracy: 0.5150 - val_loss: 1.3755 - val_accuracy: 0.5110\n","Epoch 11/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.3428 - accuracy: 0.5224 - val_loss: 1.3598 - val_accuracy: 0.5132\n","Epoch 12/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.3200 - accuracy: 0.5353 - val_loss: 1.3923 - val_accuracy: 0.5010\n","Epoch 13/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.2988 - accuracy: 0.5412 - val_loss: 1.3785 - val_accuracy: 0.5124\n","Epoch 14/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.2803 - accuracy: 0.5454 - val_loss: 1.3675 - val_accuracy: 0.5182\n","Epoch 15/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.2650 - accuracy: 0.5528 - val_loss: 1.3609 - val_accuracy: 0.5238\n","Epoch 16/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.2526 - accuracy: 0.5575 - val_loss: 1.3617 - val_accuracy: 0.5210\n","Epoch 17/100\n","1407/1407 [==============================] - 27s 20ms/step - loss: 1.2312 - accuracy: 0.5643 - val_loss: 1.3324 - val_accuracy: 0.5344\n","Epoch 18/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.2162 - accuracy: 0.5686 - val_loss: 1.3397 - val_accuracy: 0.5414\n","Epoch 19/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.2005 - accuracy: 0.5753 - val_loss: 1.3505 - val_accuracy: 0.5254\n","Epoch 20/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1906 - accuracy: 0.5802 - val_loss: 1.3785 - val_accuracy: 0.5186\n","Epoch 21/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1755 - accuracy: 0.5843 - val_loss: 1.3577 - val_accuracy: 0.5260\n","Epoch 22/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1593 - accuracy: 0.5928 - val_loss: 1.3542 - val_accuracy: 0.5284\n","Epoch 23/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1510 - accuracy: 0.5946 - val_loss: 1.3463 - val_accuracy: 0.5310\n","Epoch 24/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1393 - accuracy: 0.5992 - val_loss: 1.3280 - val_accuracy: 0.5424\n","Epoch 25/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1240 - accuracy: 0.6051 - val_loss: 1.3391 - val_accuracy: 0.5312\n","Epoch 26/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.1123 - accuracy: 0.6098 - val_loss: 1.3483 - val_accuracy: 0.5258\n","Epoch 27/100\n","1407/1407 [==============================] - 27s 20ms/step - loss: 1.0973 - accuracy: 0.6144 - val_loss: 1.3450 - val_accuracy: 0.5358\n","Epoch 28/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.0954 - accuracy: 0.6141 - val_loss: 1.3612 - val_accuracy: 0.5300\n","Epoch 29/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 1.0794 - accuracy: 0.6189 - val_loss: 1.3288 - val_accuracy: 0.5436\n","Epoch 30/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.0681 - accuracy: 0.6226 - val_loss: 1.3405 - val_accuracy: 0.5340\n","Epoch 31/100\n","1407/1407 [==============================] - 27s 20ms/step - loss: 1.0558 - accuracy: 0.6268 - val_loss: 1.3546 - val_accuracy: 0.5386\n","Epoch 32/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 1.0503 - accuracy: 0.6299 - val_loss: 1.3523 - val_accuracy: 0.5356\n","Epoch 33/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 1.0385 - accuracy: 0.6342 - val_loss: 1.3395 - val_accuracy: 0.5418\n","Epoch 34/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 1.0303 - accuracy: 0.6372 - val_loss: 1.3766 - val_accuracy: 0.5362\n","Epoch 35/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 1.0164 - accuracy: 0.6436 - val_loss: 1.3764 - val_accuracy: 0.5400\n","Epoch 36/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 1.0119 - accuracy: 0.6417 - val_loss: 1.3634 - val_accuracy: 0.5416\n","Epoch 37/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 0.9966 - accuracy: 0.6486 - val_loss: 1.3678 - val_accuracy: 0.5348\n","Epoch 38/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 0.9958 - accuracy: 0.6496 - val_loss: 1.3761 - val_accuracy: 0.5440\n","Epoch 39/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 0.9799 - accuracy: 0.6546 - val_loss: 1.3848 - val_accuracy: 0.5394\n","Epoch 40/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 0.9721 - accuracy: 0.6595 - val_loss: 1.3970 - val_accuracy: 0.5344\n","Epoch 41/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 0.9644 - accuracy: 0.6610 - val_loss: 1.3743 - val_accuracy: 0.5370\n","Epoch 42/100\n","1407/1407 [==============================] - 27s 19ms/step - loss: 0.9552 - accuracy: 0.6648 - val_loss: 1.4011 - val_accuracy: 0.5302\n","Epoch 43/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 0.9479 - accuracy: 0.6696 - val_loss: 1.4064 - val_accuracy: 0.5420\n","Epoch 44/100\n","1407/1407 [==============================] - 28s 20ms/step - loss: 0.9407 - accuracy: 0.6711 - val_loss: 1.4056 - val_accuracy: 0.5320\n","157/157 [==============================] - 1s 4ms/step - loss: 1.3280 - accuracy: 0.5424\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.3280383348464966, 0.5424000024795532]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"o550G07e8EqX"},"source":["- 이전보다 빠르게 수렴하나요? 훨씬 빠릅니다! 이전 모델은 가장 낮은 검증 손실에 도달하기 위해 27 에포크가 걸렸지만 새 모델은 동일한 손실에 도달하는데 5 에포크가 걸렸고 16 에포크까지 계속 줄어듭니다. 이전 모델보다 두 배 이상 빠릅니다. BN 층은 훈련을 안정적으로 수행하고 더 큰 학습률을 사용할 수 있기 때문에 수렴이 빨라졌습니다.\n","- BN이 더 좋은 모델을 만드나요? 네! 최종 모델의 성능이 47.6%가 아니라 54.0% 정확도로 더 좋습니다. 이는 아주 좋은 모델이 아니지만 적어도 이전보다는 낫습니다(합성곱 신경망이 더 낫겠지만 이는 다른 주제입니다. 14장을 참고하세요).\n","- BN이 훈련 속도에 영향을 미치나요? 모델이 훨씬 빠르게 수렴했지만 각 에포크는 8초가 아니라 12초가 걸렸습니다. BN 층에서 추가된 계산 때문입니다. 하지만 전반적인 훈련 시간(탁상 시계 시간)은 크게 줄었습니다!"]},{"cell_type":"markdown","metadata":{"id":"Hwypfgy7xkZ1"},"source":["d. 배치 정규화를 SELU로 바꾸어보세요. 네트워크가 자기 정규화하기 위해 필요한 변경 사항을 적용해보세요(즉, 입력 특성 표준화, 르쿤 정규분포 초기화, 완전 연결 층만 순차적으로 쌓은 심층 신경망 등)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9W5gqBaxkfR","executionInfo":{"status":"ok","timestamp":1629286506950,"user_tz":-540,"elapsed":599751,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"ff2d79bd-cd8d-42cf-c0c4-7e677dc53eff"},"source":["# 활성화 함수만 셀루로 바꿈 배치정규화도 없애고\n","keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100,\n","                                 kernel_initializer=\"lecun_normal\",\n","                                 activation=\"selu\"))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.Nadam(lr=7e-4)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n","model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n","run_index = 1 # 모델을 훈련할 때마다 증가시킴\n","run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n","\n","X_means = X_train.mean(axis=0)\n","X_stds = X_train.std(axis=0)\n","X_train_scaled = (X_train - X_means) / X_stds\n","X_valid_scaled = (X_valid - X_means) / X_stds\n","X_test_scaled = (X_test - X_means) / X_stds\n","\n","model.fit(X_train_scaled, y_train, epochs=100,\n","          validation_data=(X_valid_scaled, y_valid),\n","          callbacks=callbacks)\n","\n","model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n","model.evaluate(X_valid_scaled, y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","1407/1407 [==============================] - 21s 13ms/step - loss: 1.9176 - accuracy: 0.3125 - val_loss: 1.8557 - val_accuracy: 0.3402\n","Epoch 2/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.7046 - accuracy: 0.3943 - val_loss: 1.7404 - val_accuracy: 0.3784\n","Epoch 3/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.6085 - accuracy: 0.4348 - val_loss: 1.7106 - val_accuracy: 0.3906\n","Epoch 4/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.5486 - accuracy: 0.4558 - val_loss: 1.6228 - val_accuracy: 0.4376\n","Epoch 5/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.4902 - accuracy: 0.4764 - val_loss: 1.6360 - val_accuracy: 0.4288\n","Epoch 6/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.4453 - accuracy: 0.4922 - val_loss: 1.5338 - val_accuracy: 0.4578\n","Epoch 7/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.4072 - accuracy: 0.5069 - val_loss: 1.5670 - val_accuracy: 0.4546\n","Epoch 8/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.3681 - accuracy: 0.5220 - val_loss: 1.4677 - val_accuracy: 0.4924\n","Epoch 9/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.3350 - accuracy: 0.5354 - val_loss: 1.4917 - val_accuracy: 0.4802\n","Epoch 10/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.2991 - accuracy: 0.5463 - val_loss: 1.4928 - val_accuracy: 0.4892\n","Epoch 11/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.2714 - accuracy: 0.5580 - val_loss: 1.5010 - val_accuracy: 0.4952\n","Epoch 12/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.2473 - accuracy: 0.5666 - val_loss: 1.4967 - val_accuracy: 0.4866\n","Epoch 13/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.2225 - accuracy: 0.5737 - val_loss: 1.5072 - val_accuracy: 0.4948\n","Epoch 14/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1953 - accuracy: 0.5877 - val_loss: 1.4629 - val_accuracy: 0.4978\n","Epoch 15/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.1714 - accuracy: 0.5960 - val_loss: 1.4936 - val_accuracy: 0.5032\n","Epoch 16/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1453 - accuracy: 0.6051 - val_loss: 1.5237 - val_accuracy: 0.4946\n","Epoch 17/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.1255 - accuracy: 0.6100 - val_loss: 1.5271 - val_accuracy: 0.4992\n","Epoch 18/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.1052 - accuracy: 0.6193 - val_loss: 1.5183 - val_accuracy: 0.5020\n","Epoch 19/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 1.0896 - accuracy: 0.6230 - val_loss: 1.5875 - val_accuracy: 0.4932\n","Epoch 20/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 1.0667 - accuracy: 0.6302 - val_loss: 1.5335 - val_accuracy: 0.5026\n","Epoch 21/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0431 - accuracy: 0.6399 - val_loss: 1.5707 - val_accuracy: 0.5082\n","Epoch 22/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0252 - accuracy: 0.6444 - val_loss: 1.5599 - val_accuracy: 0.4992\n","Epoch 23/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0128 - accuracy: 0.6524 - val_loss: 1.5523 - val_accuracy: 0.5090\n","Epoch 24/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 0.9892 - accuracy: 0.6612 - val_loss: 1.5586 - val_accuracy: 0.5060\n","Epoch 25/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 2.4942 - accuracy: 0.6091 - val_loss: 1.5552 - val_accuracy: 0.4902\n","Epoch 26/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0787 - accuracy: 0.6244 - val_loss: 1.5474 - val_accuracy: 0.4908\n","Epoch 27/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 1.0159 - accuracy: 0.6467 - val_loss: 1.5210 - val_accuracy: 0.5032\n","Epoch 28/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 0.9740 - accuracy: 0.6641 - val_loss: 1.5643 - val_accuracy: 0.4964\n","Epoch 29/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 0.9427 - accuracy: 0.6729 - val_loss: 1.6226 - val_accuracy: 0.5084\n","Epoch 30/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 0.9787 - accuracy: 0.6614 - val_loss: 1.5922 - val_accuracy: 0.5040\n","Epoch 31/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 0.9193 - accuracy: 0.6829 - val_loss: 1.6214 - val_accuracy: 0.5124\n","Epoch 32/100\n","1407/1407 [==============================] - 18s 12ms/step - loss: 0.8939 - accuracy: 0.6938 - val_loss: 1.6711 - val_accuracy: 0.5088\n","Epoch 33/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 0.9747 - accuracy: 0.6668 - val_loss: 1.6003 - val_accuracy: 0.5060\n","Epoch 34/100\n","1407/1407 [==============================] - 17s 12ms/step - loss: 0.9300 - accuracy: 0.6815 - val_loss: 1.5894 - val_accuracy: 0.5032\n","157/157 [==============================] - 1s 3ms/step - loss: 1.4629 - accuracy: 0.4978\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4628735780715942, 0.49779999256134033]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCQUPivV8U-Y","executionInfo":{"status":"ok","timestamp":1629286509152,"user_tz":-540,"elapsed":1403,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"890b89cd-b0e6-4369-e4cb-21a589af5d3c"},"source":["model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n","model.evaluate(X_valid_scaled, y_valid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["157/157 [==============================] - 1s 3ms/step - loss: 1.4629 - accuracy: 0.4978\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4628735780715942, 0.49779999256134033]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"d4VVhVFqxkjP"},"source":["e. 알파 드롭아웃으로 모델에 규제를 적용해보세요. 그다음 모델을 다시 훈련하지 않고 MC 드롭아웃으로 더 높은 정확도를 얻을 수 있는지 확인해보세요."]},{"cell_type":"code","metadata":{"id":"7lqCNJwqxkoo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629303389582,"user_tz":-540,"elapsed":582920,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"d2aec9b0-60e0-4790-e338-ed523505a626"},"source":["keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100,\n","                                 kernel_initializer=\"lecun_normal\",\n","                                 activation=\"selu\"))\n","\n","model.add(keras.layers.AlphaDropout(rate=0.1))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.Nadam(lr=5e-4)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n","model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n","run_index = 1 # 모델을 훈련할 때마다 증가시킴\n","run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n","tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n","callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n","\n","X_means = X_train.mean(axis=0)\n","X_stds = X_train.std(axis=0)\n","X_train_scaled = (X_train - X_means) / X_stds\n","X_valid_scaled = (X_valid - X_means) / X_stds\n","X_test_scaled = (X_test - X_means) / X_stds\n","\n","model.fit(X_train_scaled, y_train, epochs=100,\n","          validation_data=(X_valid_scaled, y_valid),\n","          callbacks=callbacks)\n","\n","model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n","model.evaluate(X_valid_scaled, y_valid)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","1407/1407 [==============================] - 23s 14ms/step - loss: 1.8990 - accuracy: 0.3237 - val_loss: 1.7690 - val_accuracy: 0.3812\n","Epoch 2/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.6595 - accuracy: 0.4139 - val_loss: 1.6994 - val_accuracy: 0.3936\n","Epoch 3/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.5701 - accuracy: 0.4474 - val_loss: 1.5827 - val_accuracy: 0.4392\n","Epoch 4/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.5020 - accuracy: 0.4730 - val_loss: 1.5694 - val_accuracy: 0.4512\n","Epoch 5/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.4441 - accuracy: 0.4930 - val_loss: 1.5916 - val_accuracy: 0.4680\n","Epoch 6/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.3982 - accuracy: 0.5117 - val_loss: 1.5119 - val_accuracy: 0.4862\n","Epoch 7/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.3531 - accuracy: 0.5318 - val_loss: 1.5868 - val_accuracy: 0.4770\n","Epoch 8/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.3137 - accuracy: 0.5430 - val_loss: 1.4993 - val_accuracy: 0.4834\n","Epoch 9/100\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.2751 - accuracy: 0.5556 - val_loss: 1.5133 - val_accuracy: 0.4846\n","Epoch 10/100\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.2425 - accuracy: 0.5695 - val_loss: 1.4881 - val_accuracy: 0.4964\n","Epoch 11/100\n","1407/1407 [==============================] - 20s 14ms/step - loss: 1.2115 - accuracy: 0.5806 - val_loss: 1.5692 - val_accuracy: 0.4976\n","Epoch 12/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.1809 - accuracy: 0.5939 - val_loss: 1.5369 - val_accuracy: 0.4948\n","Epoch 13/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.1485 - accuracy: 0.6026 - val_loss: 1.5419 - val_accuracy: 0.5022\n","Epoch 14/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.1295 - accuracy: 0.6131 - val_loss: 1.5397 - val_accuracy: 0.5078\n","Epoch 15/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.0992 - accuracy: 0.6216 - val_loss: 1.5538 - val_accuracy: 0.5128\n","Epoch 16/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.0750 - accuracy: 0.6328 - val_loss: 1.6259 - val_accuracy: 0.5032\n","Epoch 17/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.0542 - accuracy: 0.6386 - val_loss: 1.6612 - val_accuracy: 0.4978\n","Epoch 18/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 1.0308 - accuracy: 0.6484 - val_loss: 1.6762 - val_accuracy: 0.5010\n","Epoch 19/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 1.0136 - accuracy: 0.6529 - val_loss: 1.7195 - val_accuracy: 0.4996\n","Epoch 20/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 0.9979 - accuracy: 0.6577 - val_loss: 1.7594 - val_accuracy: 0.4998\n","Epoch 21/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 0.9684 - accuracy: 0.6690 - val_loss: 1.7050 - val_accuracy: 0.5106\n","Epoch 22/100\n","1407/1407 [==============================] - 18s 13ms/step - loss: 0.9566 - accuracy: 0.6760 - val_loss: 1.6972 - val_accuracy: 0.5056\n","Epoch 23/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 0.9384 - accuracy: 0.6817 - val_loss: 1.7686 - val_accuracy: 0.4974\n","Epoch 24/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 0.9247 - accuracy: 0.6842 - val_loss: 1.7976 - val_accuracy: 0.5090\n","Epoch 25/100\n","1407/1407 [==============================] - 19s 13ms/step - loss: 0.8971 - accuracy: 0.6959 - val_loss: 1.8304 - val_accuracy: 0.5120\n","Epoch 26/100\n","1407/1407 [==============================] - 20s 14ms/step - loss: 0.8832 - accuracy: 0.7006 - val_loss: 1.8178 - val_accuracy: 0.4872\n","Epoch 27/100\n","1407/1407 [==============================] - 20s 14ms/step - loss: 0.9019 - accuracy: 0.6992 - val_loss: 1.7454 - val_accuracy: 0.5084\n","Epoch 28/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 0.8576 - accuracy: 0.7083 - val_loss: 1.8360 - val_accuracy: 0.5082\n","Epoch 29/100\n","1407/1407 [==============================] - 19s 14ms/step - loss: 0.8389 - accuracy: 0.7179 - val_loss: 1.8576 - val_accuracy: 0.5076\n","Epoch 30/100\n","1407/1407 [==============================] - 20s 14ms/step - loss: 0.8261 - accuracy: 0.7205 - val_loss: 1.8594 - val_accuracy: 0.5040\n","157/157 [==============================] - 1s 4ms/step - loss: 1.4881 - accuracy: 0.4964\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[1.4880553483963013, 0.49639999866485596]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"fBqwr4BfBLOb"},"source":["MC 드롭 써보자"]},{"cell_type":"code","metadata":{"id":"ij9sUqU3BN-B","executionInfo":{"status":"ok","timestamp":1629303389839,"user_tz":-540,"elapsed":260,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["class MCAlphaDropout(keras.layers.AlphaDropout):\n","    def call(self, inputs):\n","        return super().call(inputs, training=True)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Kk_ghZ7Bh75","executionInfo":{"status":"ok","timestamp":1629303390806,"user_tz":-540,"elapsed":378,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["# 똑같은 가중치를 가진 mc모델 생성\n","mc_model = keras.models.Sequential([\n","    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n","    for layer in model.layers\n","])"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9umWk0AB3lU"},"source":["그다음 몇 가지 유틸리티 함수를 추가합니다. 첫 번째 함수는 모델을 여러 번 실행합니다(기본적으로 10번). 그다음 평균한 예측 클래스 확률을 반환합니다. 두 번째 함수는 이 평균 확률을 사용해 각 샘플의 클래스를 예측합니다:"]},{"cell_type":"code","metadata":{"id":"k5tnHAzxB5bM","executionInfo":{"status":"ok","timestamp":1629303392099,"user_tz":-540,"elapsed":281,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n","    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n","    return np.mean(Y_probas, axis=0)\n","\n","def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n","    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n","    return np.argmax(Y_probas, axis=1)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xHAwccWUxksm"},"source":["\n","이제 검증 세트의 모든 샘플에 대해 예측을 만들고 정확도를 계산해 보죠:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIv_Npr8B7Ni","executionInfo":{"status":"ok","timestamp":1629303398589,"user_tz":-540,"elapsed":6494,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"493cfb57-9b9f-4024-ffe6-72a724fb0e4e"},"source":["keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n","accuracy = np.mean(y_pred == y_valid[:, 0])\n","accuracy"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.498"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"DnpvJd0mCCC5"},"source":["f. 1사이클 스케줄링으로 모델을 다시 훈련하고 훈련 속도와 모델 정확도가 향상되는지 확인해보세요."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XONRolK3CBCh","executionInfo":{"status":"ok","timestamp":1629303398980,"user_tz":-540,"elapsed":401,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"26ed8bd7-0dca-4c13-b070-34edbc004644"},"source":["keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100,\n","                                 kernel_initializer=\"lecun_normal\",\n","                                 activation=\"selu\"))\n","\n","model.add(keras.layers.AlphaDropout(rate=0.1))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.SGD(lr=1e-3)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"phrB8qkaJMev","executionInfo":{"status":"ok","timestamp":1629304975439,"user_tz":-540,"elapsed":243,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["import math"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"jH2KyRmAIo6P","executionInfo":{"status":"ok","timestamp":1629304977700,"user_tz":-540,"elapsed":244,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}}},"source":["def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n","    init_weights = model.get_weights()\n","    iterations = math.ceil(len(X) / batch_size) * epochs\n","    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n","    init_lr = K.get_value(model.optimizer.lr)\n","    K.set_value(model.optimizer.lr, min_rate)\n","    exp_lr = ExponentialLearningRate(factor)\n","    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n","                        callbacks=[exp_lr])\n","    K.set_value(model.optimizer.lr, init_lr)\n","    model.set_weights(init_weights)\n","    return exp_lr.rates, exp_lr.losses\n","K = keras.backend\n","\n","class ExponentialLearningRate(keras.callbacks.Callback):\n","    def __init__(self, factor):\n","        self.factor = factor\n","        self.rates = []\n","        self.losses = []\n","    def on_batch_end(self, batch, logs):\n","        self.rates.append(K.get_value(self.model.optimizer.lr))\n","        self.losses.append(logs[\"loss\"])\n","        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n","\n","def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n","    init_weights = model.get_weights()\n","    iterations = math.ceil(len(X) / batch_size) * epochs\n","    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n","    init_lr = K.get_value(model.optimizer.lr)\n","    K.set_value(model.optimizer.lr, min_rate)\n","    exp_lr = ExponentialLearningRate(factor)\n","    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n","                        callbacks=[exp_lr])\n","    K.set_value(model.optimizer.lr, init_lr)\n","    model.set_weights(init_weights)\n","    return exp_lr.rates, exp_lr.losses\n","\n","def plot_lr_vs_loss(rates, losses):\n","    plt.plot(rates, losses)\n","    plt.gca().set_xscale('log')\n","    plt.hlines(min(losses), min(rates), max(rates))\n","    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n","    plt.xlabel(\"Learning rate\")\n","    plt.ylabel(\"Loss\")\n","    \n","class OneCycleScheduler(keras.callbacks.Callback):\n","    def __init__(self, iterations, max_rate, start_rate=None,\n","                 last_iterations=None, last_rate=None):\n","        self.iterations = iterations\n","        self.max_rate = max_rate\n","        self.start_rate = start_rate or max_rate / 10\n","        self.last_iterations = last_iterations or iterations // 10 + 1\n","        self.half_iteration = (iterations - self.last_iterations) // 2\n","        self.last_rate = last_rate or self.start_rate / 1000\n","        self.iteration = 0\n","    def _interpolate(self, iter1, iter2, rate1, rate2):\n","        return ((rate2 - rate1) * (self.iteration - iter1)\n","                / (iter2 - iter1) + rate1)\n","    def on_batch_begin(self, batch, logs):\n","        if self.iteration < self.half_iteration:\n","            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n","        elif self.iteration < 2 * self.half_iteration:\n","            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n","                                     self.max_rate, self.start_rate)\n","        else:\n","            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n","                                     self.start_rate, self.last_rate)\n","        self.iteration += 1\n","        K.set_value(self.model.optimizer.lr, rate)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"f-xBFGLrCFwx","executionInfo":{"status":"ok","timestamp":1629304988091,"user_tz":-540,"elapsed":8379,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"4d40e469-e37c-421f-8c0c-0185aef4a256"},"source":["batch_size = 128\n","rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n","plot_lr_vs_loss(rates, losses)\n","plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["352/352 [==============================] - 6s 14ms/step - loss: nan - accuracy: 0.1390\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(9.999999747378752e-06,\n"," 9.615227699279785,\n"," 2.6199238300323486,\n"," 3.9377043928418844)"]},"metadata":{"tags":[]},"execution_count":24},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjTqGfpkCJ4q","executionInfo":{"status":"ok","timestamp":1629304991052,"user_tz":-540,"elapsed":269,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"461a3d85-5408-4f12-f2f6-4643e92b2499"},"source":["keras.backend.clear_session()\n","tf.random.set_seed(42)\n","np.random.seed(42)\n","\n","model = keras.models.Sequential()\n","model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n","for _ in range(20):\n","    model.add(keras.layers.Dense(100,\n","                                 kernel_initializer=\"lecun_normal\",\n","                                 activation=\"selu\"))\n","\n","model.add(keras.layers.AlphaDropout(rate=0.1))\n","model.add(keras.layers.Dense(10, activation=\"softmax\"))\n","\n","optimizer = keras.optimizers.SGD(lr=1e-2)\n","model.compile(loss=\"sparse_categorical_crossentropy\",\n","              optimizer=optimizer,\n","              metrics=[\"accuracy\"])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjR65ZJzCL0N","executionInfo":{"status":"ok","timestamp":1629305072353,"user_tz":-540,"elapsed":80312,"user":{"displayName":"전인혁","photoUrl":"","userId":"17402048460309510400"}},"outputId":"728ff680-b45b-4ae3-a5d8-dc4b14bd3136"},"source":["\n","n_epochs = 15\n","onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n","history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n","                    validation_data=(X_valid_scaled, y_valid),\n","                    callbacks=[onecycle])"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","352/352 [==============================] - 6s 16ms/step - loss: 2.0544 - accuracy: 0.2858 - val_loss: 1.7799 - val_accuracy: 0.3848\n","Epoch 2/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.7508 - accuracy: 0.3807 - val_loss: 1.6362 - val_accuracy: 0.4252\n","Epoch 3/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.6132 - accuracy: 0.4288 - val_loss: 1.6246 - val_accuracy: 0.4312\n","Epoch 4/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.5374 - accuracy: 0.4552 - val_loss: 1.6158 - val_accuracy: 0.4392\n","Epoch 5/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.4870 - accuracy: 0.4728 - val_loss: 1.6431 - val_accuracy: 0.4472\n","Epoch 6/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.4459 - accuracy: 0.4888 - val_loss: 1.5829 - val_accuracy: 0.4564\n","Epoch 7/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.4105 - accuracy: 0.5004 - val_loss: 1.5944 - val_accuracy: 0.4560\n","Epoch 8/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.3434 - accuracy: 0.5233 - val_loss: 1.4842 - val_accuracy: 0.4912\n","Epoch 9/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.2699 - accuracy: 0.5484 - val_loss: 1.5341 - val_accuracy: 0.4724\n","Epoch 10/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.1935 - accuracy: 0.5760 - val_loss: 1.5228 - val_accuracy: 0.5056\n","Epoch 11/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.1255 - accuracy: 0.6001 - val_loss: 1.5254 - val_accuracy: 0.5096\n","Epoch 12/15\n","352/352 [==============================] - 5s 15ms/step - loss: 1.0574 - accuracy: 0.6230 - val_loss: 1.4953 - val_accuracy: 0.5126\n","Epoch 13/15\n","352/352 [==============================] - 5s 15ms/step - loss: 0.9862 - accuracy: 0.6466 - val_loss: 1.5179 - val_accuracy: 0.5198\n","Epoch 14/15\n","352/352 [==============================] - 5s 15ms/step - loss: 0.9228 - accuracy: 0.6697 - val_loss: 1.5388 - val_accuracy: 0.5248\n","Epoch 15/15\n","352/352 [==============================] - 5s 15ms/step - loss: 0.8829 - accuracy: 0.6836 - val_loss: 1.5681 - val_accuracy: 0.5268\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"K3NcTRDJxk3G"},"source":[""]}]}