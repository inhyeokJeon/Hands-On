> 1. 정확히 같은 훈련 데이터로 다섯 개의 다른 모델을 훈련시켜서 모두 95% 정확도를 얻었다면 이 모델들을 연결하여 더 좋은 결과를 얻을 수 있을까요? 가능하다면 어떻게 해야 할까요? 그렇지 않다면 왜일까요?
> > 더 좋은 모델을 얻을 수 있습니다. 다섯개의 모델을 연결해 투표 앙상블을 만든다.
> 2. 직접 투표와 간접 투표 분류기 사이의 차이점은 무엇인가요?
> > 간접투표는 직접투표와 다르게 높은 확률의 클래스에 비중을 더 둔다.
> 3. 배깅 앙상블의 훈련을 여러 대의 서버에 분산시켜 속도를 높일 수 있을까요?
>    페이스팅 앙상블, 부스팅 앙상블, 랜덤 포레스트, 스태킹 앙상블의 경우는 어떨가요?
> > 배깅 앙상블과 페이스팅, 랜덤폴스트의 같은 경우는 여러 대의 서버에 분산시켜 속도를 높일 수 있다.
> > 부스팅 앙상블 같은 경우에는 앞의 모델의 결과가 다음모델의 영향을 주기 떄문에 불가능하다.
> > 스태킹 같은 경우는 가능은 하나 모든 예측기의 결과를 하나로 합산항야 하기 때문에 속도를 높히기는 어렵다고 볼 수 있다. 
> 4. oob 평가의 장점은 무엇인가요?
> > 따로 검증 세트나 테스트 세트를 구별하여 평가를 할 필요 없이 자체적으로 평가 가능하다. 
> 5. 무엇이 엑스트라 트리를 일반 랜덤 포레스트보다 더 무작위하게 만드나요?
> 추가적인 무작위성이 어떻게 도움이 될까요?
> 엑스트라 트리는 일반 랜덤포레스트보다 느릴까요, 빠를까요?
> > 후보 특성을 사용해 무작위로 분할하여 그 중 최상의 분할을 선택하는 것이 무작위하게 만든다.
> > 편향이 늘어나지만, 분산을낮추게 한다.
> > 엑스트라 트리가 일반 랜덤포레스트보다 빠르다.
> 6. 에이다부스트 앙상블이 훈련 데이터에 과소적합되었다면 어던 매개변수를 어떻게 바꾸어야 할까요?
> > 추정기 수(n_estimators)를 높히고, 규제를 약하게한다. 또한 학습률을 높혀야 한다.
> 7. 그레이디언트 부스팅 앙상블이 훈련 데이터에 과대적합되었다면 학습률을 높여야 할까요, 낮춰야 할가요?
> > 낮춰야함. 또한 알맞은 학습률을 찾기위해 조기 종료 기법을 사용할 수 있어야 한다.